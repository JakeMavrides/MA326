{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-g-uwqUQi94"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "MA 326\n",
        "Code for homework 3: SVM\n",
        "\"\"\"\n",
        "from matplotlib.pyplot import imread\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def boundaries(binarized,axis):\n",
        "    # variables named assuming axis = 0; algorithm valid for axis=1\n",
        "    # [1,0][axis] effectively swaps axes for summing\n",
        "    rows = np.sum(binarized,axis = [1,0][axis]) > 0\n",
        "    rows[1:] = np.logical_xor(rows[1:], rows[:-1])\n",
        "    change = np.nonzero(rows)[0]\n",
        "    ymin = change[::2]\n",
        "    ymax = change[1::2]\n",
        "    height = ymax-ymin\n",
        "    too_small = 10 # real letters will be bigger than 10px by 10px\n",
        "    ymin = ymin[height>too_small]\n",
        "    ymax = ymax[height>too_small]\n",
        "    return tuple(zip(ymin,ymax))"
      ],
      "metadata": {
        "id": "pZpnFFkBQlmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separate(img):\n",
        "    orig_img = img.copy()\n",
        "    pure_white = 255.\n",
        "    white = np.max(img)\n",
        "    black = np.min(img)\n",
        "    thresh = (white+black)/2.0\n",
        "    binarized = img<thresh\n",
        "    row_bounds = boundaries(binarized, axis = 0)\n",
        "    cropped = []\n",
        "    for r1,r2 in row_bounds:\n",
        "        img = binarized[r1:r2,:]\n",
        "        col_bounds = boundaries(img, axis=1)\n",
        "        print(col_bounds)\n",
        "        rects = [r1,r2,col_bounds[0][0],col_bounds[0][1]]\n",
        "        cropped.append(np.array(orig_img[rects[0]:rects[1],rects[2]:rects[3]]/pure_white))\n",
        "    return cropped\n"
      ],
      "metadata": {
        "id": "4GK_T2OLQm6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "big_img = imread(\"d.png\")\n",
        "grey_big_img = big_img[:,:,0]*0.21+big_img[:,:,1]*0.72+big_img[:,:,2]*0.07 # convert to gray-scale image\n",
        "grey_big_img = grey_big_img*255\n",
        "grey_big_img = grey_big_img.astype(\"int\")\n",
        "print(np.min(grey_big_img))\n",
        "print(np.max(grey_big_img))\n",
        "plt.imshow(grey_big_img,cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "imgs = separate(grey_big_img) # separates big_img (pure white = 255) into array of little images (pure white = 1.0)\n",
        "for img in imgs:\n",
        "    img = resize(img, (10,10))\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8r1h0Iv3QoDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def partition(data, target, p):\n",
        "  # EDIT: Realized last minute that we need to shuffle data,\n",
        "  # luckily sklearn has built in shuffle function\n",
        "  data, target = shuffle(data, target, random_state=42)\n",
        "\n",
        "  split_point = int(len(data) * p) # Finds index to split array at\n",
        "\n",
        "  # partitioning:\n",
        "  train_data = data[:split_point]\n",
        "  test_data = data[split_point:]\n",
        "  train_target = target[:split_point]\n",
        "  test_target = target[split_point:]\n",
        "\n",
        "  return train_data, train_target, test_data, test_target"
      ],
      "metadata": {
        "id": "uQauiVg6cCF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in column pictures\n",
        "# Note: each column contains 8 samples\n",
        "d_col_img = imread('d.png')\n",
        "e_col_img = imread('e.png')\n",
        "f_col_img = imread('f.png')\n",
        "\n",
        "# Convert to greyscale\n",
        "grey_d_col = d_col_img[:,:,0]*0.21+d_col_img[:,:,1]*0.72+d_col_img[:,:,2]*0.07\n",
        "grey_d_col = (grey_d_col*255).astype('int')\n",
        "\n",
        "grey_e_col = e_col_img[:,:,0]*0.21+e_col_img[:,:,1]*0.72+e_col_img[:,:,2]*0.07\n",
        "grey_e_col = (grey_e_col*255).astype('int')\n",
        "\n",
        "grey_f_col = f_col_img[:,:,0]*0.21+f_col_img[:,:,1]*0.72+f_col_img[:,:,2]*0.07\n",
        "grey_f_col = (grey_f_col*255).astype('int')\n",
        "\n",
        "# Create image lists using separate function\n",
        "d_imgs = separate(grey_d_col)\n",
        "e_imgs = separate(grey_e_col)\n",
        "f_imgs = separate(grey_f_col)\n",
        "\n",
        "# Create truth labels\n",
        "d_labels = np.zeros(8) # Note: could change 8 out for 'len(d_imgs)' for alterations\n",
        "e_labels = np.ones(8)\n",
        "f_labels = np.full(8, 2)"
      ],
      "metadata": {
        "id": "inCZGP9NcxF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error concatenating unless elements of the letter_imgs are the same, so resizing:\n",
        "resize_d_imgs = [resize(img, (10, 10)) for img in d_imgs]\n",
        "resize_e_imgs = [resize(img, (10, 10)) for img in e_imgs]\n",
        "resize_f_imgs = [resize(img, (10, 10)) for img in f_imgs]\n",
        "\n",
        "# Combine data and labels\n",
        "data = np.concatenate((resize_d_imgs, resize_e_imgs, resize_f_imgs), axis=0)\n",
        "labels = np.concatenate((d_labels, e_labels, f_labels), axis=0)\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3V8BBp_fGos",
        "outputId": "06a1470a-4e5e-446d-c2aa-dd2c32c8811a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels, test_data, test_labels = partition(data, labels, .75)\n",
        "train_data = np.array([img.flatten() for img in train_data])\n",
        "test_data = np.array([img.flatten() for img in test_data])"
      ],
      "metadata": {
        "id": "2Fyo_B_lgXcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(kernel='linear')\n",
        "svc.fit(train_data, train_labels)\n",
        "preds = svc.predict(test_data)\n",
        "acc = accuracy_score(test_labels, preds) * 100"
      ],
      "metadata": {
        "id": "Xo9oujGPgpxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prediction:\", preds.astype(int))\n",
        "print(\"Truth:\", test_labels.astype(int))\n",
        "print(\"Accuracy: \", acc, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SOZk1FVh7Vu",
        "outputId": "196faf8f-23ee-402f-b769-11270bb80a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [2 0 1 1 2 0]\n",
            "Truth: [2 0 1 1 2 0]\n",
            "Accuracy:  100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q7:#\n",
        "Not sure if my handwriting or picture quality was just really good or consistent, or if the fact that I picked such different looking characters (d, e, and f) had a positive impact, but unless I drop to just 1 training sample, my accuracy is 100%. With just one sample it drops to 63.7%."
      ],
      "metadata": {
        "id": "qx4RhWk8jGTE"
      }
    }
  ]
}