{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5: \n",
    "- K-Means Clustering\n",
    "\n",
    "__Optional Reading Material:__\n",
    "- [Scikit-learn: K-Means Clustering](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "- [Visualizing K-Means clustering](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### k-Means Clustering\n",
    "The idea of k-means clustering is to group a set of data points into $k$ clusters, such that we make the clusters as clustered, or as concentrated, as possible. So, if we wish to cluster into clusters $\\{D_1, D_2, . . . D_{k}\\}$, then we wish to minimize the total within-cluster variation:\n",
    "$$\n",
    "\\displaystyle\\sum_{i=1}^{k}\\sum_{x\\in D_i} d(x,\\mu_i)^2.\n",
    "$$\n",
    "\n",
    "\n",
    "When clustering, the points are clustered very much dependently on each other. Usually, the distance function is the Euclidean distance. It is not usually feasible to search the space of all possible solutions, so some fast optimization algorithm is used (sometimes several times). In sklearn, you as a user can control what method is used. k-Means clustering is faster and more robust if the data is as low-dimensional as possible. This means that linearly correlated variables should be combined. This is called __dimensionality reduction__.\n",
    "\n",
    "__k-Means clustering__ is implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 0], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=  np.array([[1,1,3,4],\n",
    "              [2,1,5,5],\n",
    "              [5,5,1,2],\n",
    "              [5,4,1,3],\n",
    "              [5,5,1,1]])\n",
    "kmeans = KMeans(4)\n",
    "kmeans.fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if you look at the data, these are likely the clusters that you would have detected intuitively.\n",
    "\n",
    "Here's a more complicated example:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html#sphx-glr-auto-examples-cluster-plot-cluster-iris-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
